#!/usr/bin/env python
import argparse
import sys
from BeautifulSoup import BeautifulSoup
import urllib2

#
#      ___         ___                                                     ___           ___          
#     /\  \       /\  \                                                   /\  \         /\__\        
#    /::\  \      \:\  \                                     ___         /::\  \       /:/ _/_      
#   /:/\:\__\      \:\  \                                   /\__\       /:/\:\  \     /:/ /\  \    
#  /:/ /:/  /  ___  \:\  \   ___     ___   ___     ___     /:/  /      /:/ /::\  \   /:/ /::\  \   
# /:/_/:/  /  /\  \  \:\__\ /\  \   /\__\ /\  \   /\__\   /:/__/      /:/_/:/\:\__\ /:/__\/\:\__\ 
# \:\/:/  /   \:\  \ /:/  / \:\  \ /:/  / \:\  \ /:/  /  /::\  \      \:\/:/  \/__/ \:\  \ /:/  / 
#  \::/__/     \:\  /:/  /   \:\  /:/  /   \:\  /:/  /  /:/\:\  \      \::/__/       \:\  /:/  /   
#   \:\  \      \:\/:/  /     \:\/:/  /     \:\/:/  /   \/__\:\  \      \:\  \        \:\/:/  /     
#    \:\__\      \::/  /       \::/  /       \::/  /         \:\__\      \:\__\        \::/  /       
#     \/__/       \/__/         \/__/         \/__/           \/__/       \/__/         \/__/       
#
# Author: Jared Marshall Hall 
# Modified by: Zachary Parchman
# License: MIT License
# Contact: hall.jared.m@gmail.com
# Created: August 21, 2015
# Purpose: Easily and quickly scrape html tags by name, id, and class. Return
# full tag text, id name, class name, or just src or href links. 
# Why: To my knowledge there are libraries, but there aren't any programs
# designed specifically for this purpose.   
# Uses: Can be use with a website name as input, or a pipe. 

parser = argparse.ArgumentParser()

if sys.stdin.isatty():
    parser.add_argument('website', help='Name of website.')

parser.add_argument('tag', help='Tag to search for. Defaults to "all"', nargs='?', const='all', type=str)
parser.add_argument('-id', '--id-name', nargs='?', const='_', help='Search for specific tag id, defaults to show all tags with an id.', dest='id', required=False)
parser.add_argument('-cl', '--class-name', nargs='?', const='_', help='Search for specific tag class, defaults to show all tags with a class.', dest='class', required=False)
parser.add_argument('-src', '--src-only', help='Show src links only.', action='store_true', required=False)
parser.add_argument('-href', '--href-only', help='Show href links only.', action='store_true', required=False)
parser.add_argument('-names', '--names-only', help='Use with the -id or the -cl flags to show only the names of the ids/classes.', action='store_true', required=False)
args = vars(parser.parse_args())

def pick_tag_on_part( lst ):
    if args['src_only']:
        return  map( lambda x : x.get('src'), lst )
    elif args['href_only']:
        return  map( lambda x : x.get('href'), lst )
    elif args['names_only']:
        return  map( lambda x : x.get('id'), lst )
    #return a copy of the list if nothing will be filtered
    return lst[:]


def print_str(item):
    print str(item)

def filter_by_attribute( lst , t ):
    ret = filter( lambda x : x.get(t) is not None , lst)

    if args[t] != '_' :
        tags_returned_2 = filter( lambda x : x.get(t) == args[t], ret)
    
    ret = pick_tag_on_part(ret)
    ret = filter( None , ret )
    return ret

def get_soup():
    stream = None
    if 'website' in args:
        WEBSITE = args['website']
        if "http" not in WEBSITE:
            WEBSITE = "http://" + WEBSITE
        page = urllib2.urlopen(WEBSITE)
        stream = page.read()
    else:
        stream = sys.stdin.read()

    return BeautifulSoup( stream )

soup = get_soup()

if str(args['tag']) == "all":
    tags_returned = soup.findAll(True)
else:
    tags_returned = soup.findAll(args['tag'])
if not tags_returned:
    sys.exit()

if  args['id'] :
    tags_returned_2 = filter_by_attribute(tags_returned, 'id')
elif args['class']:
    tags_returned_2 = filter_by_attribute(tags_returned, 'class')

tags_returned_2 = pick_tag_on_part( tags_returned )
tags_returned_2 = filter(None, tags_returned_2)

map( print_str, tags_returned_2)
