#!/usr/bin/env python
import argparse
import sys
from BeautifulSoup import BeautifulSoup
import urllib2
import jcolor 

#
#      ___         ___                                                     ___           ___          
#     /\  \       /\  \                                                   /\  \         /\__\        
#    /::\  \      \:\  \                                     ___         /::\  \       /:/ _/_      
#   /:/\:\__\      \:\  \                                   /\__\       /:/\:\  \     /:/ /\  \    
#  /:/ /:/  /  ___  \:\  \   ___     ___   ___     ___     /:/  /      /:/ /::\  \   /:/ /::\  \   
# /:/_/:/  /  /\  \  \:\__\ /\  \   /\__\ /\  \   /\__\   /:/__/      /:/_/:/\:\__\ /:/__\/\:\__\ 
# \:\/:/  /   \:\  \ /:/  / \:\  \ /:/  / \:\  \ /:/  /  /::\  \      \:\/:/  \/__/ \:\  \ /:/  / 
#  \::/__/     \:\  /:/  /   \:\  /:/  /   \:\  /:/  /  /:/\:\  \      \::/__/       \:\  /:/  /   
#   \:\  \      \:\/:/  /     \:\/:/  /     \:\/:/  /   \/__\:\  \      \:\  \        \:\/:/  /     
#    \:\__\      \::/  /       \::/  /       \::/  /         \:\__\      \:\__\        \::/  /       
#     \/__/       \/__/         \/__/         \/__/           \/__/       \/__/         \/__/       
#
# Author: Jared Marshall Hall
# License: MIT License
# Contact: hall.jared.m@gmail.com
# Created: August 21, 2015
# Purpose: Easily and quickly scrape html tags by name, id, and class. Return full tag text, id name, class name, or just src or href links. 
# Why: To my knowledge there are libraries, but there aren't any programs designed specifically for this purpose.   
# Uses: Can be use with a website name as input, or a pipe. 
# Installation: Can be added to usr/local/bin like so (for calling straight from the command line regardless of current folder):
#         cd /usr/local/bin (command below must be called from within this folder)
#         sudo ln -s <path_to_pulltag/pulltag>  (add symbolic link to pulltag.. make sure jcolor.py is in the same directory as original pulltag)
#         chmod +x pulltag (make pulltag executable)
#
#     Donate Bitcoin:
#     1AYk yF8P 1k19 NpAA xxEm WBa6 rp7g wgHz dr
#
#     Donate Dogecoin:
#     DBGX4dwhD7SHhfcgzKjSZ2yJDhruAPgPUP
#
#     Donate via Paypal:
#     http://bit.ly/1klxN1M
#

# TODO remove debug messages
# TODO make colors better
# TODO ascii art

parser = argparse.ArgumentParser()

if sys.stdin.isatty():
    parser.add_argument('website', help='Name of website.')

parser.add_argument('tag', help='Tag to search for. Defaults to "all"', nargs='?', const='all', type=str)
parser.add_argument('-c', '--color-mode', help='Turn colors on.', action='store_true', required=False)
parser.add_argument('-id', '--id-name', nargs='?', const='_', help='Search for specific tag id, defaults to show all tags with an id.', dest='id', required=False)
parser.add_argument('-cl', '--class-name', nargs='?', const='_', help='Search for specific tag class, defaults to show all tags with a class.', dest='class', required=False)
parser.add_argument('-src', '--src-only', help='Show src links only.', action='store_true', required=False)
parser.add_argument('-href', '--href-only', help='Show href links only.', action='store_true', required=False)
parser.add_argument('-names', '--names-only', help='Use with the -id or the -cl flags to show only the names of the ids/classes.', action='store_true', required=False)
args = vars(parser.parse_args())

def pick_tag_on_part( lst ):
    if (args['src_only']):
        return  map( lambda x : x.get('src'), lst )
    elif (args['href_only']):
        return  map( lambda x : x.get('href'), lst )
    elif (args['names_only']):
        return  map( lambda x : x.get('id'), lst )
    #return a copy of the list if nothing will be filtered
    return lst[:]


def print_str(item):
    print str(item)

def filter_by_attribute( lst , t ):
    ret = filter( lambda x : x.get(t) is not None , lst)

    if args[t] != '_' :
        tags_returned_2 = filter( lambda x : x.get(t) == args[t], ret)
    
    ret = pick_tag_on_part(ret)
    ret = filter( None , ret )
    return ret

def get_soup():
    stream = None
    if 'website' in args:
        WEBSITE = args['website']
        if ("http" not in WEBSITE):
            WEBSITE = "http://" + WEBSITE
        page = urllib2.urlopen(WEBSITE)
        stream = page.read()
    else:
        stream = sys.stdin.read()

    return BeautifulSoup( stream )

def color_tags( tags ):
    def color_src( tt ):
        return jcolor.FGYELLOW + str( tt ) + jcolor.ENDC
    def color_href( tt ):
        return jcolor.FGORANGE + str( tt ) + jcolor.ENDC
    def color_names( tt ):
        return jcolor.FGORANGE + str( tt ) + jcolor.ENDC
    def color_none( tt ):
        return jcolor.FGGREEN + str( tt ) + jcolor.ENDC

    if (args['src_only']):
        return map(color_src, tags)
    elif (args['href_only']):
        return map(color_href, tags)
    elif (args['names_only']):
        return map(color_names, tags)
    else:
        return map(color_none, tags)

# colors not enabled
soup = get_soup()

if (str(args['tag']) == "all"):
    tags_returned = soup.findAll(True)
else:
    tags_returned = soup.findAll(args['tag'])
if not tags_returned:
    sys.exit()

if ( args['id'] ):
    tags_returned_2 = filter_by_attribute(tags_returned, 'id')
elif args['class']:
    tags_returned_2 = filter_by_attribute(tags_returned, 'class')

tags_returned_2 = pick_tag_on_part( tags_returned )
tags_returned_2 = filter(None, tags_returned_2)

if not args['color_mode'] :
    map( print_str, tags_returned_2)
else:
    strs = color_tags( tags_returned_2 )
    map ( print_str, strs );
